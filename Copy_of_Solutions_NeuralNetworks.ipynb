{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "9Sz2c5LlU7Sj",
        "tUjr5CKnhvtg",
        "hXud5MuBXqzo",
        "j09evSD_YfJ4",
        "37O_VE_D1Bdy",
        "GqrfI4JiVeFr",
        "7Y1wGoQPm2Ko",
        "BGPXO0mm8Uc9"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RakshitaRuparel/Neural-Network-CSclub/blob/main/Copy_of_Solutions_NeuralNetworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiM6gYg0nhkY"
      },
      "source": [
        "<font color=\"red\"><h1><b> * MAKE A COPY OF THIS NOTEBOOK SO YOUR EDITS ARE SAVED *</b></h1></font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>üê∂<b><i> Neural Networks: Classifying Images for a Self-Driving Car</i></b></h1>"
      ],
      "metadata": {
        "id": "xZDFpdSJz7ww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "# **üîé Introduction**"
      ],
      "metadata": {
        "id": "ZX7thGJj0bcp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq-JhCcLpBwS"
      },
      "source": [
        "\n",
        "We work for CC: ConscientiousCars, where we help self-driving vehicles be more conscientious of their surroundings. Our cars have been very good at recognizing and avoiding humans. They haven't, however, been capable of recognizing dogs. Since dogs are man's best friend and will always be where we humans are, we want our cars to know if a dog is on the road in front of them and avoid the dog!\n",
        "\n",
        "The first step to avoiding these cute puppies is **knowing if a puppy is in front of the car**. So today we will **build a detector that can tell the difference between a dog and a road in front of it**!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents"
      ],
      "metadata": {
        "id": "vLdE8vzi0ZD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can find a more detailed Table of Contents by clicking on the icon on the left sidebar that looks like this: <img src=\"https://drive.google.com/uc?export=view&id=1AGUz4POrRWu_6n5yI_YdO4qFRr41_PzE\" width=20>.\n",
        "\n",
        ">[üîé Introduction](#scrollTo=ZX7thGJj0bcp)\n",
        "\n",
        ">>[Table of Contents](#scrollTo=vLdE8vzi0ZD7)\n",
        "\n",
        ">[üìä Milestone 1: Data Exploration](#scrollTo=1QxGsnvhnn8R)\n",
        "\n",
        ">>[1.1. Introducing the Data](#scrollTo=btr24O6Hqgo6)\n",
        "\n",
        ">>[1.2. Understanding our Data Representation](#scrollTo=PHS0E_3wt0RS)\n",
        "\n",
        ">[(Optional) üèò Milestone 2: K-Nearest Neighbors (KNN)](#scrollTo=tUjr5CKnhvtg)\n",
        "\n",
        ">[üß† Milestone 3: Neural Networks](#scrollTo=doLXp1Ot8D2C)\n",
        "\n",
        ">>[3.1. Building a Neural Network using Scikit-Learn](#scrollTo=pabMQ8tIv9Ef)\n",
        "\n",
        ">[(Optional) üñº Milestone 4: Convolutional Neural Networks](#scrollTo=37O_VE_D1Bdy)\n",
        "\n",
        ">>[(Optional) 4.1. CNNClassifier Class Background](#scrollTo=GqrfI4JiVeFr)\n",
        "\n",
        ">>[4.2. Using the CNNClassifier](#scrollTo=9GjIRoWe0DzQ)\n",
        "\n",
        ">>[4.3. Training and Validation Curves](#scrollTo=c-XRh5Y5P_CL)\n",
        "\n",
        ">[(Optional Challenge) üîç Milestone 5: Explainability through Saliency Maps](#scrollTo=7Y1wGoQPm2Ko)\n",
        "\n",
        ">[ü§î Knowledge Check](#scrollTo=Yswq2Dyvd6jU)\n",
        "\n",
        ">[üìã Cheat Sheets](#scrollTo=XPr7W1g93cSe)\n",
        "\n"
      ],
      "metadata": {
        "id": "ss3IL0IM0YYs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhNVum16scIW",
        "cellView": "form"
      },
      "source": [
        "#@title **üèó Setup Cell**\n",
        "#@markdown **Run this to import libraries and download data!**\n",
        "\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Inspirit's util file and discussion exercise answer handler\n",
        "!wget -q \"https://storage.googleapis.com/inspirit-ai-data-bucket-1/Modules/inspiritai_util.py\"\n",
        "from inspiritai_util import handle_discussion_response\n",
        "\n",
        "# Loading in data\n",
        "def load_data():\n",
        "  !wget -q --show-progress -O cifar_data https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%201%20-%205/Session%204%20_%205%20-%20Neural%20Networks%20_%20CNN/dogs_v_roads\n",
        "\n",
        "  import pickle\n",
        "  data_dict = pickle.load(open( \"cifar_data\", \"rb\" ));\n",
        "\n",
        "  data   = data_dict['data']\n",
        "  labels = data_dict['labels']\n",
        "\n",
        "  return data, labels\n",
        "\n",
        "data, labels = load_data()\n",
        "\n",
        "# Function for plotting images\n",
        "def plot_one_image(data, labels, img_idx):\n",
        "  from google.colab.patches import cv2_imshow\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  img   = data[img_idx, :].reshape([32,32,3]).copy()\n",
        "  label = labels[img_idx]\n",
        "\n",
        "  fig, ax = plt.subplots(1,1)\n",
        "  img = ax.imshow(img.astype('uint8'), extent=[-1,1,-1,1])\n",
        "\n",
        "  x_label_list = [0, 8, 16, 24, 32]\n",
        "  y_label_list = [0, 8, 16, 24, 32]\n",
        "\n",
        "  ax.set_xticks([-1, -0.5, 0, 0.5, 1])\n",
        "  ax.set_yticks([-1, -0.5, 0, 0.5, 1])\n",
        "\n",
        "  ax.set_xticklabels(x_label_list)\n",
        "  ax.set_yticklabels(y_label_list)\n",
        "\n",
        "  ax.set_title(f'Image: {img_idx} | Label: {label}')\n",
        "\n",
        "  display(fig)\n",
        "  plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QxGsnvhnn8R"
      },
      "source": [
        "---\n",
        "---\n",
        "# **üìä Milestone 1: Data Exploration**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btr24O6Hqgo6"
      },
      "source": [
        "## 1.1. Introducing the Data\n",
        "\n",
        "Let's take a look at the dataset that can help our car's model tell the difference between roads and dogs. The dataset has been loaded in as `data` (the images) and `labels` (the classifications of each of the images). Note that we won't be working with Pandas DataFrames in this notebook since we're working with image data.\n",
        "\n",
        "Try running the cell below and changing the number to see what changes!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csXB_FPMrx1D"
      },
      "source": [
        "plot_one_image(data, labels, 0) # Change this number"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYRzHTxVdSTG"
      },
      "source": [
        "### 1.1.1. Discussion Exercise\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown *Why might we be using such blurry images?*\n",
        "answer = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "handle_discussion_response(answer)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_TohrGI_KVQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instructor Solution\n",
        "<details><summary> click to reveal! </summary>\n",
        "\n",
        "Due to ease of processing and storage limitations, we use 32x32 pixel RGB images for our dataset of 1200 images. This choice also accommodates how camera quality may vary with motion and from car to car, and speeds up model training due to the smaller number of weights needed to process lower resolution images.\n"
      ],
      "metadata": {
        "id": "YPRW3PQ2RN5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's try out a road image if you haven't already. Again, try changing the number:"
      ],
      "metadata": {
        "id": "hnGnklImRU2z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsRj6BAqs25Y"
      },
      "source": [
        "plot_one_image(data, labels, 700) # Change this number"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0Qx4UYxdbTK"
      },
      "source": [
        "How many images do we have? Let's take a look at the length of the data using the familiar `len()` function below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LQXCiGmAmz-"
      },
      "source": [
        "print(len(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.2. Discussion Exercise\n",
        "\n",
        "Run the code cell below to use the `Counter` class in Python, which is a quick and easy way of counting up the number of times each label shows up."
      ],
      "metadata": {
        "id": "MEe7ShGhMkrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Counter(labels))"
      ],
      "metadata": {
        "id": "O7e_REg8Mi54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown *How many of each do we have? Why would it be important we have this amount of each?*\n",
        "answer = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "handle_discussion_response(answer)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Uzo3VvW_NB-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OojOPMbLAl2B"
      },
      "source": [
        "#### Instructor Solution\n",
        "<details><summary> click to reveal! </summary>\n",
        "\n",
        "The dataset is organized such that there are 600 images of dogs and 600 images of roads. If we didn't have equal amounts of each label, our model would become biased toward the label that has more data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sz2c5LlU7Sj"
      },
      "source": [
        "### (Optional) 1.1.3. Coding Exercise\n",
        "\n",
        "> Try this out if you want to use a for loop to look at more images in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the code cell below to use a for loop to plot multiple images using the `plot_one_image()` function.\n",
        "\n",
        "If you're not sure how to write for loops in Python, ask your instructor or feel free to refer to the [for loop reference at the end of the notebook](#scrollTo=BGPXO0mm8Uc9)!"
      ],
      "metadata": {
        "id": "tdDKc2SOOBfu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkcqdB2ZVoNc"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Instructor Solution\n",
        "\n",
        "# NOTE: Data is organized so 0-499 + 1000-1099 are dogs, and 500-999 + 1100-1199\n",
        "# are roads. Any for loop that prints out 5 of each from those ranges is valid\n",
        "\n",
        "for i in range(5):\n",
        "  plot_one_image(data, labels, i)\n",
        "\n",
        "for i in range(700, 705):\n",
        "  plot_one_image(data, labels, i)"
      ],
      "metadata": {
        "id": "BVCLOgJIEqUv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHS0E_3wt0RS"
      },
      "source": [
        "## 1.2. Understanding our Data Representation\n",
        "\n",
        "Let's see what the raw data looks like. The cell below will print out `data[0]` for you, which is the first image.\n",
        "\n",
        "> The `data[0]` notation is our way of telling Python which of the items we want from a list of items (in this case, which image we want out of the whole array of images in `data`). You can change the `0` like you did with `plot_one_image()` to see what different images may look like in numerical format!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlgF6jWit9jz"
      },
      "source": [
        "print('One image looks like:', data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That doesn't give us the whole picture, so run the cell below to see the length of the list of numbers representing the image."
      ],
      "metadata": {
        "id": "UuTI0YedRbY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Length of list:\", len(data[0]))"
      ],
      "metadata": {
        "id": "lqp-RFEqP2uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPu7IDsZU_On"
      },
      "source": [
        "### 1.2.1. Discussion Question"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWBX6fWUui4R",
        "cellView": "form"
      },
      "source": [
        "#@markdown *Using the images we plotted earlier and what you've learned about how color images are stored, fill in the blanks below!*\n",
        "\n",
        "image_height_in_pixels = 0 #@param {type:\"integer\"}\n",
        "image_width_in_pixels = 0 #@param {type:\"integer\"}\n",
        "number_of_colors_per_pixel = 0 #@param {type:\"integer\"}\n",
        "\n",
        "if image_height_in_pixels == 32 and image_width_in_pixels == 32 and number_of_colors_per_pixel == 3:\n",
        "  print(\"Correct!\")\n",
        "  print(f\"Each image is {image_height_in_pixels}x{image_width_in_pixels} pixels.\")\n",
        "  print(f\"Each pixel has {number_of_colors_per_pixel} channels (for Red, Green, and Blue)\")\n",
        "else:\n",
        "  print(\"Those aren't quite the values.\")\n",
        "  print(f\"Your values give a total of {image_height_in_pixels * image_width_in_pixels * number_of_colors_per_pixel} intensity values per image.\")\n",
        "  print(\"Discuss with your group and try again!\")\n",
        "\n",
        "\n",
        "#@markdown *Once you're happy with your answers, run the cell to check if they're correct!*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown *With this in mind, what do each of the numbers represent in the lists we saw above?*\n",
        "answer = \"\" # @param {\"type\":\"string\"}\n",
        "handle_discussion_response(answer)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "R2UvY4J0YT_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instructor Solution\n",
        "\n",
        "<details><summary> click to reveal! </summary>\n",
        "\n",
        "Each number represents the intensity of a color channel. We have 8 bits of info per channel or 256 possible values (ranging 0-255). Three color channels make up one color pixel (R G B). We have images that are 32 pixels wide and 32 pixels tall so $32 * 32 = 1024$ gives the total number of pixels, and multiplying this by the number of channels gives $3 * 1024 = 3072$, the total number of intensity values!\n"
      ],
      "metadata": {
        "id": "4YpV8uCERnQ_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-haNvnOwt-YE"
      },
      "source": [
        "These numerical values are used as **inputs** to represent the image in order to predict an **output** label: 'dog' or 'road'!\n",
        "\n",
        "Here's a quick look at our entire dataset before we move on to trying out some models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZIiCuBrvS6z"
      },
      "source": [
        "print('Data shape:', data.shape)\n",
        "print('Data:\\n', data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's go ahead and split our data into training and testing sets! We've provided the code for this in the cell below; go ahead and run it!"
      ],
      "metadata": {
        "id": "hZYS3f5GwW8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing data and create training and test inputs and labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=1)"
      ],
      "metadata": {
        "id": "0D2hVt3uwXiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUjr5CKnhvtg"
      },
      "source": [
        "---\n",
        "---\n",
        "# (Optional) **üèò Milestone 2: K-Nearest Neighbors (KNN)**\n",
        "\n",
        "> Try out this section if you want a quick scikit-learn warm-up before jumping into neural networks. Feel free to skip during class if you feel comfortable with KNNs and want more time to experiment with neural networks and convolutional neural networks (CNNs)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8_JZ9PVzKzr"
      },
      "source": [
        "### 2.1.1. Coding Exercise\n",
        "**Playground:** Explore [this demo](http://vision.stanford.edu/teaching/cs231n-demos/knn/) to understand what the KNN model is doing!\n",
        "\n",
        "**Exercise:** Below, please build, train, and measure the accuracy of your own KNN model. We've provided the first line of code that initializes the model for you. Experiment with changing the number of neighbors!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFOgS2VEyTkH"
      },
      "source": [
        "# 1. Initialize KNN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=1) # Experiment with different numbers of neighbors!\n",
        "\n",
        "# 2. Train the model on the training images/labels\n",
        "\n",
        "\n",
        "# 3. Get the model's predictions on the testing data\n",
        "\n",
        "\n",
        "# 4. Print the accuracy score on the testing data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUtugsglYkSJ",
        "cellView": "form"
      },
      "source": [
        "#@title Instructor Solution\n",
        "\n",
        "# 1. Initialize KNN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=2)\n",
        "\n",
        "# 2. Train the model on the training images/labels\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Get the model's predictions on the testing data\n",
        "y_pred = knn_model.predict(X_test)\n",
        "\n",
        "# 4. Print the accuracy score on the testing data\n",
        "print(\"KNN Testing Set Accuracy:\")\n",
        "print(accuracy_score(y_test, y_pred) * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you continue to tweak your KNN model, use the next two code cells to dive deeper! What kinds of mistakes is your model making? Can you find specific examples of pictures where it's getting it wrong?"
      ],
      "metadata": {
        "id": "4Tzm4JRZGM8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Run this to display the confusion matrix for your model!\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred, labels=['dog', 'road'])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cnf_matrix,\n",
        "                              display_labels=['dog', 'road'])\n",
        "disp.plot(cmap='Blues')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RnzFPhUjCZlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title {'run' : 'auto'}\n",
        "#@markdown ### Choose an image index to display the image and your model's prediction!\n",
        "\n",
        "# Specify which image you want to show\n",
        "image_id = 0 # @param {\"type\":\"slider\",\"min\":0,\"max\":240,\"step\":1}\n",
        "\n",
        "# Visualize the image\n",
        "plot_one_image(X_test, y_test, image_id)\n",
        "\n",
        "# Use the model to predict what this might be and print it\n",
        "print('prediction:', y_pred[image_id])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cxPuFWsFGIrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1ZgBtyIHYr7"
      },
      "source": [
        "### (Optional) 2.1.2. Discussion Exercise\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown *After you've built your KNN model, remove `random_state=1` from the train-test split and re-run that cell and the KNN training cell.*\n",
        "\n",
        "#@markdown *How does removing `random_state=1` affect your accuracy? Why do you think that is?*\n",
        "answer = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "handle_discussion_response(answer)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Wshtn0KTuftm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructor Solution\n",
        "\n",
        "<details><summary> click to reveal! </summary>\n",
        "\n",
        "Eliminating the `random_state=1` parameter changes how the data is split between the training and testing sets. Since computers cannot truly be random in that they execute specific calculations asked of them, computers cannot generate truly random numbers and instead generate pseudorandom numbers. The generator algorithms take in a \"seed\" that will always result in the same \"random\" numbers produced. This means using the same seed will always give you the same train-test split!\n",
        "\n",
        "For extra exploration, try changing the `shuffle` parameter, which is `True` by default, to see what happens when the data isn't randomly split between the training and testing sets."
      ],
      "metadata": {
        "id": "SuFQmYhWR8hn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ9uYgKMCX-z"
      },
      "source": [
        "### 2.1.3. Discussion Exercise"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown *What are the advantages and disadvantages of using a bigger vs. smaller **k**? What is the optimal value for this dataset?*\n",
        "answer = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "handle_discussion_response(answer)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e8DRsgh_uFUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instructor Solution\n",
        "\n",
        "<details><summary> click to reveal! </summary>\n",
        "\n",
        "A smaller $k$-value is effective for distinct clusters but will be sensitive to outliers and noise. A larger $k$ suits datasets with overlapping clusters but will decrease the influence of the closest data.\n",
        "\n",
        "For this dataset, an optimal $k$ is typically found to be either 2 or between 11-16."
      ],
      "metadata": {
        "id": "iJGrMK1iSeSE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oW_Wb-1CTfB"
      },
      "source": [
        "### 2.1.4. Coding Exercise\n",
        "\n",
        "Determine the optimal value of $k$ for our data. Use a for loop to loop through different values of $k$. In particular, *at the very least* try $k$ = 1, 3, 5, 10, 20, and 30. For each of these values of $k$, define a new KNN model, train it, and evaluate the accuracy.\n",
        "\n",
        "If you're not sure how to write for loops in Python, ask your instructor and feel free to refer to the [for loop reference at the end of the notebook](#scrollTo=BGPXO0mm8Uc9)!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrZK_qoAZOAd"
      },
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgjefvviV3HN",
        "cellView": "form"
      },
      "source": [
        "#@title Instructor Solution\n",
        "\n",
        "for i in [1, 3, 5, 10, 20, 30]:\n",
        "  # Defining our classifier\n",
        "  knn_model = KNeighborsClassifier(n_neighbors=i)\n",
        "\n",
        "  # Training our model with its training input data and labels\n",
        "  knn_model.fit(X_train, y_train)\n",
        "\n",
        "  # predictions for test\n",
        "  y_pred = knn_model.predict(X_test)\n",
        "\n",
        "  # Print the score on the testing data\n",
        "  print(f\"KNN testing set accuracy for {i} neighbors: {accuracy_score(y_test, y_pred)*100}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSx8HEhHKxFd"
      },
      "source": [
        "### 2.1.5. Discussion Exercise\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown *What patterns did you notice? What are some reasons that the model makes mistakes?*\n",
        "answer = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "handle_discussion_response(answer)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Iu1dNNMGvXju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instructor Solution\n",
        "\n",
        "<details><summary> click to reveal! </summary>\n",
        "\n",
        "Generally the false classifications are images that are much closer to the subject. One reason the model may make mistakes is that these images are on the boundaries of their clusters."
      ],
      "metadata": {
        "id": "i4cY1UFoTE1i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doLXp1Ot8D2C"
      },
      "source": [
        "---\n",
        "---\n",
        "# **üß† Milestone 3: Neural Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's create some new models using neural networks! If you haven't already, please play around with [TensorFlow Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.62283&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&regularization_hide=true&regularizationRate_hide=true&learningRate_hide=true&batchSize_hide=true&stepButton_hide=true&activation_hide=true) to get a feel for how neural nets work."
      ],
      "metadata": {
        "id": "eb7ClXWn9ACX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Building a Neural Network using Scikit-Learn"
      ],
      "metadata": {
        "id": "pabMQ8tIv9Ef"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9iFe-B4zqQA"
      },
      "source": [
        "To build a simple neural network, we use `MLPClassifier` from scikit-learn. We will play with the **number of neurons** and the **number of hidden layers** to adjust the complexity of our model, just like we did in Playground!\n",
        "\n",
        "**Example 1:**\n",
        "Here's how we create a neural network with 1 hidden layer of 3 neurons.\n",
        "\n",
        "```python\n",
        "nnet_model = MLPClassifier(hidden_layer_sizes=(3))\n",
        "```\n",
        "\n",
        "**Example 2:**\n",
        "\n",
        "Here's how we create a neural network with 2 hidden layers: one of 3 neurons and one of 4 neurons.\n",
        "\n",
        "```python\n",
        "nnet_model = MLPClassifier(hidden_layer_sizes=(3, 4))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1. Coding Exercise\n",
        "How might you build a neural network with more hidden layers? Fill out the code below to train and test your model!\n",
        "\n",
        "We've provided the first line for you, but you should change around the `hidden_layer_sizes` parameter to improve your results."
      ],
      "metadata": {
        "id": "9sOCUy7iTPVs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4XblMWBzm96"
      },
      "source": [
        "# 1. Initialize neural network model\n",
        "nnet_model = MLPClassifier(hidden_layer_sizes=(3), random_state=1, max_iter=1000000)\n",
        "\n",
        "# 2. Train the model on the training images/labels\n",
        "\n",
        "\n",
        "# 3. Get the model's predictions on the testing data\n",
        "\n",
        "\n",
        "# 4. Print the accuracy score on the testing data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Instructor Solution (3-Layer MLP Example)\n",
        "\n",
        "# NOTE: this is an example - have your students find a better architecture.\n",
        "\n",
        "# Create and train our multi layer perceptron model\n",
        "nnet_model = MLPClassifier(hidden_layer_sizes=(10, 5, 4), random_state=1, max_iter= 1000000)\n",
        "\n",
        "# 2. Train the model on the training images/labels\n",
        "nnet_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Get the model's predictions on the testing data\n",
        "y_pred = nnet_model.predict(X_test)\n",
        "\n",
        "# 4. Print the accuracy score on the testing data\n",
        "print(\"MLP Testing Accuracy:\")\n",
        "print(accuracy_score(y_test, y_pred) * 100)"
      ],
      "metadata": {
        "id": "6OAOvtduPV3j",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you continue to tweak your neural network, use the next two code cells to dive deeper! What kinds of mistakes is your model making? Can you find specific examples of pictures where it's getting it wrong?"
      ],
      "metadata": {
        "id": "VJffZD38DZ40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Run this to display the confusion matrix for your model!\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred, labels=['dog', 'road'])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cnf_matrix,\n",
        "                              display_labels=['dog', 'road'])\n",
        "disp.plot(cmap='Blues')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_1JuGFF3M-VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az1_moLl9E0B",
        "cellView": "form"
      },
      "source": [
        "#@title {'run' : 'auto'}\n",
        "#@markdown ### Choose an image index to display the image and your model's prediction!\n",
        "\n",
        "# Specify which image you want to show\n",
        "image_id = 0 # @param {\"type\":\"slider\",\"min\":0,\"max\":240,\"step\":1}\n",
        "\n",
        "# Visualize the image\n",
        "plot_one_image(X_test, y_test, image_id)\n",
        "\n",
        "# Use the model to predict what this might be and print it\n",
        "print('prediction:', y_pred[image_id])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1QYZTxq0RCV"
      },
      "source": [
        "**How well did your neural network perform?**\n",
        "\n",
        "Multilayer perceptrons are more complex models and it can be difficult to find the right \"settings\" for them. It takes some trial and error!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXud5MuBXqzo"
      },
      "source": [
        "### (Optional) 3.1.2. Coding Exercise\n",
        "\n",
        "> Try this out if you'd like to use a for loop to automate testing out different layer architectures!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to what you might have done for KNNs, use a for loop to automate your investigation. Explore different numbers of hidden layers, the size of the hidden layers, and the number of iterations! How well can you get your network performing?\n",
        "\n",
        "If you're not sure how to write for loops in Python, ask your instructor and feel free to refer to the [for loop reference at the end of the notebook](#scrollTo=BGPXO0mm8Uc9)!"
      ],
      "metadata": {
        "id": "T0HRKnAqZiIM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owrF6cDvX0HX"
      },
      "source": [
        "### YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDtG4wESX263",
        "cellView": "form"
      },
      "source": [
        "#@title Instructor Solution\n",
        "for layers in [(1,1), (3,3), (5,5), (8,6), (10,10,10), (10,10,5)]:\n",
        "\n",
        "  print('Layers:', layers)\n",
        "  nnet_model = MLPClassifier(hidden_layer_sizes=layers, random_state=1, max_iter=1000000)  ## How many hidden layers? How many neurons does this have?\n",
        "\n",
        "  nnet_model.fit(X_train, y_train)\n",
        "\n",
        "  # Predict what the classes are based on the testing data\n",
        "  y_pred = nnet_model.predict(X_test)\n",
        "\n",
        "  # Print the score on the testing data\n",
        "  print(\"MLP Testing Accuracy:\")\n",
        "  print(accuracy_score(y_test, y_pred) * 100)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j09evSD_YfJ4"
      },
      "source": [
        "### (Optional) 3.1.3. Coding Exercise\n",
        "\n",
        "> Try this out if you'd like to use code to find the specific examples of where your model is making errors."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our classifications are OK, but are they good enough for our conscientious cars? Let's put on our detective hats to determine the root causes of the incorrect classifications!\n",
        "\n",
        "Below, please print out 4 images of true positives, 4 images of true negatives, 4 images of false positives, and 4 images of false negatives. We've provided the code for printing 4 true positives below.\n",
        "\n",
        "What are the reasons for failure (both for false positives and false negatives)?"
      ],
      "metadata": {
        "id": "S5tUqqK2b5CV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWy1S_gyGoJT"
      },
      "source": [
        "# True Positives (code provided)\n",
        "print (\"TRUE POSITIVES\")\n",
        "tp_count = 0\n",
        "i = 0\n",
        "while tp_count < 4 and i < len(X_test):\n",
        "  if y_pred[i] == y_test[i] and y_pred[i] == 'dog':\n",
        "    plot_one_image(X_test, y_test, i)\n",
        "    tp_count += 1\n",
        "  i += 1\n",
        "\n",
        "# False Positives\n",
        "### YOUR CODE HERE\n",
        "\n",
        "# True Negatives\n",
        "### YOUR CODE HERE\n",
        "\n",
        "# False Negatives\n",
        "### YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU-cZuCnG7Yy",
        "cellView": "form"
      },
      "source": [
        "#@title Instructor Solution\n",
        "\n",
        "# True Positives\n",
        "print (\"TRUE POSITIVES\")\n",
        "tp_count = 0\n",
        "i = 0\n",
        "while tp_count < 4 and i < len(X_test):\n",
        "  if y_pred[i] == y_test[i] and y_pred[i] == 'dog':\n",
        "    plot_one_image(X_test, y_test, i)\n",
        "    tp_count += 1\n",
        "  i += 1\n",
        "\n",
        "\n",
        "# False Positives\n",
        "print (\"FALSE POSITIVES\")\n",
        "fp_count = 0\n",
        "i = 0\n",
        "while fp_count < 4 and i < len(X_test):\n",
        "  if y_pred[i] != y_test[i] and y_pred[i] == 'dog':\n",
        "    plot_one_image(X_test, y_test, i)\n",
        "    fp_count += 1\n",
        "  i += 1\n",
        "\n",
        "\n",
        "# True Negatives\n",
        "print (\"TRUE NEGATIVES\")\n",
        "tn_count = 0\n",
        "i = 0\n",
        "while tn_count < 4 and i < len(X_test):\n",
        "  if y_pred[i] == y_test[i] and y_pred[i] == 'road':\n",
        "    plot_one_image(X_test, y_test, i)\n",
        "    tn_count += 1\n",
        "  i += 1\n",
        "\n",
        "\n",
        "# False Negatives\n",
        "print (\"FALSE NEGATIVES\")\n",
        "fn_count = 0\n",
        "i = 0\n",
        "while fn_count < 4 and i < len(X_test):\n",
        "  if y_pred[i] != y_test[i] and y_pred[i] == 'road':\n",
        "    plot_one_image(X_test, y_test, i)\n",
        "    fn_count += 1\n",
        "  i += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37O_VE_D1Bdy"
      },
      "source": [
        "---\n",
        "---\n",
        "# (Optional) **üñº Milestone 4: Convolutional Neural Networks**\n",
        "\n",
        "> There is a famous type of neural network known as convolutional neural networks (CNNs), which work particularly well on computer vision problems. You can try them out in this section, but note that there's another lecture and notebook that goes more in-depth with these!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **üèó Run this cell to define the `CNNClassifier`!**\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape\n",
        "\n",
        "def logits_to_one_hot_encoding(input):\n",
        "    \"\"\"\n",
        "    Converts softmax output (logits) to a one-hot encoded format.\n",
        "\n",
        "    This function takes an array of softmax output probabilities\n",
        "    (usually from a neural network's output layer) and converts\n",
        "    each row to a one-hot encoded vector. The highest probability\n",
        "    in each row is marked as 1, with all other values set to 0.\n",
        "\n",
        "    Parameters:\n",
        "    input (numpy.ndarray): A 2D array where each row contains softmax probabilities for each class.\n",
        "                            The shape of the array is (n_samples, n_classes).\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: A 2D array of the same shape as the input, where each row is the one-hot encoded representation\n",
        "                   of the class with the highest probability in the original row.\n",
        "    \"\"\"\n",
        "\n",
        "    output = np.zeros_like(input, dtype=int)\n",
        "    output[np.arange(len(input)), np.argmax(input, axis=1)] = 1\n",
        "    return output\n",
        "\n",
        "def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "    history = history.history\n",
        "    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "    history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "    if not ax:\n",
        "      f, ax = plt.subplots(1,1)\n",
        "    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n",
        "    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')\n",
        "    ax.legend(loc = 7)\n",
        "    ax.set_ylim([0.4, 1])\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel('Accuracy (Fraction)')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def categorical_to_onehot(labels_in):\n",
        "  labels = []\n",
        "  for label in labels_in:\n",
        "    if label == 'dog':\n",
        "      labels.append(np.array([1, 0]))\n",
        "    else:\n",
        "      labels.append(np.array([0, 1]))\n",
        "  return np.array(labels)\n",
        "\n",
        "class CNNClassifier:\n",
        "    \"\"\"\n",
        "    A Convolutional Neural Network (CNN) classifier using Keras, customized for binary classification tasks.\n",
        "\n",
        "    This class wraps a Keras Sequential model with a specific architecture suitable for image classification tasks.\n",
        "    It includes a custom `predict` method that outputs one-hot encoded predictions, and other standard Keras model\n",
        "    methods are accessible as well. This was done to override the need for the SciKeras wrappers that is frequently\n",
        "    incompatible with Google Colab versions of Keras & Tensorflow. Feel free to modify as needed.\n",
        "\n",
        "    Attributes:\n",
        "        num_epochs (int): The number of training epochs.\n",
        "        layers (int): The number of convolutional layers in the model.\n",
        "        dropout (float): The dropout rate used in dropout layers for regularization.\n",
        "        model (keras.models.Sequential): The underlying Keras Sequential model.\n",
        "\n",
        "    Methods:\n",
        "        build_model(): Constructs the CNN model with the specified architecture and compiles it.\n",
        "\n",
        "        fit(*args, **kwargs): Trains the model. Accepts arguments compatible with the Keras `fit` method.\n",
        "\n",
        "        predict(*args, **kwargs): Predicts labels for the input data. Converts the softmax output of the model\n",
        "                                  to one-hot encoded format using `logits_to_one_hot_encoding`. Necessary to match\n",
        "                                  accuracy_score function expected arguments.\n",
        "\n",
        "        predict_proba(*args, **kwargs): Predicts labels for the input data and returns the raw output of the softmax.\n",
        "                                        Used when wanting to inspect the raw probabilistic scoring of the model.\n",
        "\n",
        "    Usage:\n",
        "        cnn_classifier = CNNClassifier(num_epochs=30, layers=4, dropout=0.5)\n",
        "        cnn_classifier.fit(X_train, y_train)\n",
        "        predictions = cnn_classifier.predict(X_test)\n",
        "\n",
        "    Note:\n",
        "        The `__getattr__` method is overridden to delegate attribute access to the underlying Keras model,\n",
        "        except for the `predict` method which is customized.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_epochs=30, layers=4, dropout=0.5):\n",
        "        self.num_epochs = num_epochs\n",
        "        self.layers = layers\n",
        "        self.dropout = dropout\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Reshape((32, 32, 3)))\n",
        "\n",
        "        for i in range(self.layers):\n",
        "          model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "          model.add(Activation('relu'))\n",
        "\n",
        "        model.add(Conv2D(32, (3, 3)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(self.dropout))\n",
        "\n",
        "        model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Conv2D(64, (3, 3)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(self.dropout))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dropout(self.dropout))\n",
        "        model.add(Dense(2))\n",
        "        model.add(Activation('softmax'))\n",
        "        opt = keras.optimizers.RMSprop(learning_rate=0.0001)\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def fit(self, *args, **kwargs):\n",
        "        return self.model.fit(*args, epochs=self.num_epochs, batch_size=10, verbose=2, **kwargs)\n",
        "\n",
        "    #NOTE: WRITTEN TO RETURN ONE HOT ENCODINGS FOR ACCURACY\n",
        "    def predict(self, *args, **kwargs):\n",
        "        predictions = self.model.predict(*args, **kwargs)\n",
        "        return logits_to_one_hot_encoding(predictions)\n",
        "\n",
        "    def predict_proba(self, *args, **kwargs):\n",
        "        predictions = self.model.predict(*args, **kwargs)\n",
        "        return predictions\n",
        "\n",
        "    def score(self, X, y):\n",
        "        predictions = self.predict(X)\n",
        "        return accuracy_score(y, predictions)\n",
        "\n",
        "    def __getattr__(self, name):\n",
        "        if name != 'predict' and name != 'predict_proba':\n",
        "            return getattr(self.model, name)\n",
        "        else:\n",
        "            raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{name}'\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gVRaV54p16jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqrfI4JiVeFr"
      },
      "source": [
        "## (Optional) 4.1. `CNNClassifier` Class Background\n",
        "\n",
        "> Read through this section if you want more details on how the custom `CNNClassifier` works. You can also take a look at the code defining the `CNNClassifier` in the code cell above!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Overview\n",
        "The `CNNClassifier` is a custom class designed for Inspirit AI focusing on teaching the application of Convolutional Neural Networks (CNN) for binary classification tasks using Keras. This class is unique and is not available from any standard libraries or repositories.\n",
        "\n",
        "### Description\n",
        "This class encapsulates a Keras Sequential model tailored for image classification. It features a customized `predict` method for one-hot encoded outputs, which bypasses the need for SciKeras wrappers that often present compatibility issues with certain versions of Keras and TensorFlow on Google Colab. The design encourages experimentation and modification to suit different learning or project needs. Take a look in the large import box above to see its definition!\n",
        "\n",
        "### Attributes\n",
        "- `num_epochs` (int): Number of training epochs.\n",
        "- `layers` (int): Number of convolutional layers.\n",
        "- `dropout` (float): Dropout rate for regularization.\n",
        "- `model` (keras.models.Sequential): The base Keras Sequential model.\n",
        "\n",
        "### Methods\n",
        "- `build_model()`: Sets up the CNN architecture and compiles the model.\n",
        "- `fit(*args, **kwargs)`: Trains the model using parameters compatible with Keras‚Äôs `fit` method.\n",
        "- `predict(*args, **kwargs)`: Outputs one-hot encoded predictions.\n",
        "- `predict_proba(*args, **kwargs)`: Provides raw softmax output for detailed probabilistic analysis.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sGGG0nx89XfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. Using the `CNNClassifier`"
      ],
      "metadata": {
        "id": "9GjIRoWe0DzQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before trying out the `CNNClassifier`, we need to do some more processing of the data. The `CNNClassifier` class is built using the more advanced libraries Tensorflow/Keras, which require the data to be in a different format.\n",
        "\n",
        "Specifically, we need to convert our inputs from integers (no decimal places) to floating point numbers (or floats, which have decimals). We also have to convert our labels to one-hot encodings, where we have columns for specific categories, with `1`s in the column corresponding to the data point's label and `0`s everywhere else.\n",
        "\n",
        "We've provided the code to do this for you. Run the cell below to process the data!"
      ],
      "metadata": {
        "id": "ZMt1lSvY04IA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert our inputs data to floats (decimals) for our CNN\n",
        "X_train = X_train.astype(float)\n",
        "X_test = X_test.astype(float)\n",
        "\n",
        "# Convert our output labels to one-hot vectors!\n",
        "y_test_onehot = categorical_to_onehot(y_test)\n",
        "y_train_onehot = categorical_to_onehot(y_train)"
      ],
      "metadata": {
        "id": "QcL3CrP308lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.1. Coding Exercise\n",
        "\n",
        "For initiating a basic CNN, execute the following command:\n",
        "\n",
        "```python\n",
        "cnn = CNNClassifier(num_epochs=N)\n",
        "```\n",
        "\n",
        "Here, `num_epochs` denotes the number of times the neural network will look through the entire training dataset while training.\n",
        "\n",
        "In the code cell below, create, train and test the `CNNClassifier`. Make sure you use the correct data when training and testing the model!"
      ],
      "metadata": {
        "id": "bOps2gP79fcd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSwghlVU4WTy"
      },
      "source": [
        "# 1. Initialize the CNN\n",
        "\n",
        "\n",
        "# 2. Train the CNN\n",
        "\n",
        "\n",
        "# 3. Predict what the classes are based on the testing data\n",
        "\n",
        "\n",
        "# 4. Print the score on the testing data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVozcO7TYWdn",
        "cellView": "form"
      },
      "source": [
        "#@title Instructor Solution\n",
        "\n",
        "# 1. Initialize the CNN\n",
        "cnn = CNNClassifier(num_epochs=40)\n",
        "\n",
        "# 2. Train the CNN\n",
        "cnn.fit(X_train, y_train_onehot)\n",
        "\n",
        "# 3. Predict what the classes are based on the testing data\n",
        "predictions = cnn.predict(X_test)\n",
        "\n",
        "# 4. Print the score on the testing data\n",
        "print(\"CNN Testing Set Score:\")\n",
        "print(accuracy_score(y_test_onehot, predictions) * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2.2. Discussion Exercise"
      ],
      "metadata": {
        "id": "adde03uC66G_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown *1. What was your best accuracy? Is this good enough?*\n",
        "answer_1 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown *2. You and your classmates may have a different max accuracy. Why might that be?*\n",
        "answer_2 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "handle_discussion_response(answer_1, answer_2)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rg--z8S-65WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructor Solution\n",
        "\n",
        "<details><summary> click to reveal! </summary>\n",
        "\n",
        "1. Best accuracy will vary, but it'll likely be in the 90s, increasing as number of epochs increases. Answers on whether this is good enough will also vary, as this is a bit of a moral judgment and there's no right answer here! This is a good opportunity to have a discussion where we draw the line in trusting AI to do the job of driving cars, who gets to make that decision, and the potential of overfitting (the accuracy above is on the *training* data, which the model *should* be doing well on)! The overfitting discussion can transition well into the next section on training/validation curves.\n",
        "\n",
        "2. Hint: *Consider the stages in the machine learning process.* The data is split into training and testing sets randomly, so the model learns from varying data each time. Additionally, neural network performance is influenced by multiple parameters, such as initialization, which can result in different outcomes."
      ],
      "metadata": {
        "id": "9-F39fv3TicV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGWpgsVXP1ut"
      },
      "source": [
        "CNNs typically perform better than basic Neural Networks on vision problems - but like basic Neural Networks, they aren't always consistent in their results and are sensitive to a number of factors.\n",
        "\n",
        "If you're interested in learning more about CNNs, spend some time exploring the [CNN Explainer](https://poloclub.github.io/cnn-explainer/)!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-XRh5Y5P_CL"
      },
      "source": [
        "## 4.3. Training and Validation Curves\n",
        "\n",
        "An important aspect of training neural networks is to prevent overfitting. **How do you know when your model is overfitting?**\n",
        "\n",
        "To plot our model's history, we can train it with:\n",
        "\n",
        "```python\n",
        "history = MODEL.fit(X_train, y_train_onehot, validation_data=(X_test, y_test_onehot))\n",
        "```\n",
        "\n",
        "and then use the following custom function:\n",
        "\n",
        "```python\n",
        "plot_acc(history)\n",
        "```\n",
        "\n",
        "Don't forget to change `MODEL` to be the name of your own model variable!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eaFvE2PQEFe"
      },
      "source": [
        "### 4.3.1. Coding Exercise\n",
        "\n",
        "Train another `CNNClassifier` and plot the train vs. test curve.\n",
        "\n",
        "Take a look at the plot and figure out where the model begins to overfit! Overfitting occurs when the validation accuracy starts to drop below the training accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsVAasDbjARJ"
      },
      "source": [
        "### YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMsb61vccItm",
        "cellView": "form"
      },
      "source": [
        "#@title Instructor Solution\n",
        "\n",
        "cnn = CNNClassifier(num_epochs=20)\n",
        "\n",
        "history = cnn.fit(X_train, y_train_onehot, validation_data=(X_test, y_test_onehot))\n",
        "\n",
        "plot_acc(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y1wGoQPm2Ko"
      },
      "source": [
        "---\n",
        "---\n",
        "# (Optional Challenge) **üîç Milestone 5: Explainability through Saliency Maps**\n",
        "\n",
        "> Try out this section if you want to see what your CNN is focusing on in a picture when making its decisions! Be sure to run the code in Milestone 4 before trying out this section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnGTR2Vdb08i"
      },
      "source": [
        "Neural networks have achieved incredible results in many fields. But they have a big problem: it‚Äôs very difficult to explain exactly why a neural network makes the decisions it does. This makes it difficult to trust them in high-stakes applications like medicine, self-driving cars, and criminal justice - would you trust an AI that diagnosed you with a disease, but couldn‚Äôt explain why?\n",
        "\n",
        "Other classifiers are much more explainable:\n",
        "\n",
        "*   With logistic regression, we can see the coefficient (importance) attached to each input feature.\n",
        "*   With a decision tree, we can trace a particular decision down the tree.\n",
        "*   With KNN, we can examine the nearby neighbors.\n",
        "\n",
        "Our CNN, above, works well. For example, let's try choosing an image from our dataset and classifying it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmU6Peb7m67F"
      },
      "source": [
        "image_index = 220 # pick any image you'd like\n",
        "input_image = X_test[image_index]\n",
        "print(input_image.shape)\n",
        "print(input_image) # How many numbers are there? What does each represent?\n",
        "\n",
        "plt.imshow(input_image.reshape(32,32,3).astype(int))\n",
        "plt.show()\n",
        "\n",
        "print('Classification:')\n",
        "if(np.argmax(cnn.predict(np.array([input_image]))) == 0):\n",
        "  print(\"Predicted: Dog\")\n",
        "else:\n",
        "  print(\"Predicted: Road\")\n",
        "# 0 means dog, 1 means road"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6P7DX_WcfOU"
      },
      "source": [
        "But why did the CNN reach that decision? It‚Äôs really hard to give a clear answer! The CNN relies on multiplying input features by the weights it has set. You can print out and look at the hundreds of weights:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8M8UZCgcpqO"
      },
      "source": [
        "# Warning: expect a large output!\n",
        "for layer_weights in history.model.weights:\n",
        "  print (layer_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR42boMgczoF"
      },
      "source": [
        "Unfortunately, that probably didn‚Äôt help you make a useful explanation.\n",
        "\n",
        "Researchers are currently studying ways to make neural networks more explainable. One approach is using **saliency maps** to figure out the saliency (importance) of each individual pixel. Check out a demo [here](https://lrpserver.hhi.fraunhofer.de/image-classification). Intuitively, we're trying to understand the neural network by tracking what it \"pays attention\" to, in the same way that psychologists study babies' cognition by [tracking what babies look at](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3259733/).\n",
        "\n",
        "In this exercise, we're going to build a simple version of a saliency map for the image you chose above. We'll see what pixels were most important in helping the network make its classification.\n",
        "\n",
        "To do this, we'll investigate the effects of changing each pixel a little bit. If changing a particular pixel changes the result a lot, we conclude that pixel must be important for classifying. If changing that pixel doesn't change the result, we conclude that pixel is unimportant.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RpZL6ChfLZ6"
      },
      "source": [
        "We're going to use the raw predicted probabilities, rather than the final classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkdMS7sJfR6j"
      },
      "source": [
        "pred = cnn.predict_proba(np.array([input_image])) # What does each number mean?\n",
        "print(pred)\n",
        "dog_prob = pred[0][0] # This is the probability we'll use (if we know dog prob, we know the classification)\n",
        "\n",
        "print('Probability of dog:')\n",
        "print(dog_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xla3j0R1geJY"
      },
      "source": [
        "Now, we need to calculate the saliency for each pixel (really, each RGB value). The core idea is that a pixel's saliency is the average value of\n",
        "\n",
        " $D = \\left|\\frac{\\Delta probability}{\\Delta pixel}\\right|$\n",
        "\n",
        " where $\\Delta$ is the amount of change. If a small change in the pixel value results in a large change in the probability (either up or down), we know this pixel is important. If you've seen derivatives in calculus, this idea should feel familiar.\n",
        "\n",
        "Here's the game plan:\n",
        "\n",
        "*   Consider each pixel value in turn: R, G, B, then the next pixel.\n",
        "*   Make a copy of the image array before you change anything!\n",
        "*   Make the pixel value larger or smaller by various amounts. Each time, find the CNN's prediction with the changed value, and calculate the value of D.\n",
        "*   Repeat the previous step a few times, and calculate the pixel's saliency: the average value of D.\n",
        "*   Store the saliency of each pixel in a list, so that we can visualize it later.\n",
        "\n",
        "Try it below! (Warning: this code might be very slow. As a further challenge, try to speed it up!)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnABhKUJmNCF"
      },
      "source": [
        "saliencies = [] # eventually, will be the same size as input_image\n",
        "\n",
        "for index, pixel in enumerate(input_image):\n",
        "  # index counts up from 0, pixel is between 0 and 255\n",
        "\n",
        "  if index % 100 == 0: # will track progress - this might take a while\n",
        "    print (index)\n",
        "\n",
        "  changed_input = input_image.copy() # make sure not to change the original input_image!\n",
        "\n",
        "  # YOUR CODE HERE:\n",
        "  # In changed_input, change the value of this pixel by some amount.\n",
        "  # Use the CNN to classify changed_input.\n",
        "  # Calculate the value of D.\n",
        "  # Repeat with various-size changes, and calculate saliency as the average D.\n",
        "  saliency = 0 # Change this!\n",
        "\n",
        "  saliencies.append(saliency)\n",
        "\n",
        "print(saliencies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFpQH9ZpjQ-A",
        "cellView": "form"
      },
      "source": [
        "#@title Faster Student submitted solution\n",
        "# Thanks to Paul Cherian (Inspirit AI Winter 2020 Student) for this solution!\n",
        "\n",
        "saliencies = [] #eventually, will be the same size as input_image\n",
        "all_changed_pixels = []\n",
        "pixel_differences = []\n",
        "for index, pixel in enumerate(input_image):\n",
        "  #index counts up from 0, pixel is between 0 and 255\n",
        "  # if index%100 == 0: #will track progress - this might take a while\n",
        "    # print (index)\n",
        "  # if index>500:\n",
        "  #   break\n",
        "  changed_input = input_image.copy() #make sure not to change the original input_image!\n",
        "\n",
        "  # A much faster approach would be vectorize - create an array with all the changed\n",
        "  #versions so that we can feed them all into the CNN at the same time.\n",
        "  D_list = []\n",
        "  changed_versions_of_pixel = []\n",
        "\n",
        "  for pixel_change in [-50, -30, -10, 10, 30, 50]:\n",
        "    changed_pixel = pixel + pixel_change\n",
        "\n",
        "    if 0 <= changed_pixel <= 255:\n",
        "      #add all the changed pixels to a list\n",
        "      changed_versions_of_pixel.append(changed_pixel)\n",
        "      pixel_differences.append(pixel- changed_pixel)\n",
        "\n",
        "  # add the list of changed pixels to another list\n",
        "  all_changed_pixels.append(changed_versions_of_pixel)\n",
        "\n",
        "# make a 'stack' of all images with their changed pixel in each by using the\n",
        "#changed input as the template and then reverting it back to the original when\n",
        "# we move to the next pixel\n",
        "changed_images = []\n",
        "\n",
        "for j in range(len(changed_input)):\n",
        "    for i in range(len(all_changed_pixels[j])):\n",
        "      changed_input[j]= all_changed_pixels[j][i]\n",
        "      changed_images.append(changed_input)\n",
        "      changed_input = input_image.copy()\n",
        "\n",
        "a = cnn.predict_proba(np.array([input_image]))\n",
        "b = cnn.predict_proba(np.array(changed_images))\n",
        "\n",
        "a = np.log(a)\n",
        "b = np.log(b)\n",
        "\n",
        "dog_prob = a[0][0]\n",
        "new_b = []\n",
        "for i in b:\n",
        "  new_b.append(abs(i[0]) + abs(i[1]))\n",
        "new_b = np.array(new_b)\n",
        "probability_changes = new_b - dog_prob\n",
        "d_total = abs(probability_changes/pixel_differences)\n",
        "\n",
        "# the d_total list is all the values of D for each pixel with it's changes, it\n",
        "# needs to be averaged, but because we ommitted some changed values that were not\n",
        "# in the 0-255 range, use 'start' to 'end' to splice the array.\n",
        "\n",
        "start = 0\n",
        "end = 0\n",
        "for i in all_changed_pixels:\n",
        "  end += len(i)\n",
        "  saliency = (np.mean(d_total[start:end]))\n",
        "  start = end\n",
        "  saliencies.append(saliency)\n",
        "\n",
        "print(\"Non-Normalized Saliencies: \\n\", saliencies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9jaa4VMvFTr",
        "cellView": "form"
      },
      "source": [
        "#@title Instructor Solution\n",
        "#Slow, simpler version.\n",
        "#A much faster approach would be vectorize - create an array with all the changed\n",
        "#versions so that we can feed them all into the CNN at the same time.\n",
        "\"\"\"\n",
        "saliencies = []\n",
        "for index, pixel in enumerate(input_image):\n",
        "  if index%100 == 0: #track progress\n",
        "    print (index)\n",
        "  changed_input = input_image.copy()\n",
        "  D_list = []\n",
        "  for pixel_change in [-50, -30, -10, 10, 30, 50]:\n",
        "    changed_pixel = pixel + pixel_change\n",
        "    if 0 <= changed_pixel <= 255:\n",
        "      changed_input[index] = changed_pixel\n",
        "      changed_pred = cnn.predict_proba(np.array([changed_input]))\n",
        "      changed_dog_prob = changed_pred[0][0]\n",
        "      D = (changed_dog_prob - dog_prob)/pixel_change\n",
        "      D_list.append(np.abs(D))\n",
        "  saliency = np.mean(D_list)\n",
        "  saliencies.append(saliency)\n",
        "\n",
        "print (saliencies)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJEAJ5VinTIZ"
      },
      "source": [
        "You'll notice that your saliencies are probably very small values, since each individual pixel has a small effect on the output.\n",
        "Here are the current min and max:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5vRrciYnZgk"
      },
      "source": [
        "sal_array = np.array(saliencies)\n",
        "print (sal_array.min(), sal_array.max())\n",
        "print (sal_array.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwQfwv6rnl--"
      },
      "source": [
        "To plot the saliencies, we need to do some arithmetic to transform them to a range of 0 to 1. Can you explain the function of each line?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL_W9k0W0Sai"
      },
      "source": [
        "sal_array = np.array(saliencies)\n",
        "sal_array = sal_array - sal_array.min()\n",
        "#TODO print min and max\n",
        "\n",
        "sal_array = sal_array / sal_array.max()\n",
        "#TODO print min and max\n",
        "\n",
        "#Can you perform this transformation in a single line of code?\n",
        "\n",
        "print (sal_array.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP5IbZf8pl-l"
      },
      "source": [
        "#@title Instructor Solution\n",
        "print (sal_array.min(), sal_array.max())\n",
        "sal_array = (sal_array - sal_array.min()) / (sal_array.max() - sal_array.min())\n",
        "print (sal_array.min(), sal_array.max())\n",
        "sal_array.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvFKoff4n_gf"
      },
      "source": [
        "Finally, we can plot our saliency map!\n",
        "\n",
        "If you're not getting great results, try experimenting with how much you're changing the pixel values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vANcgvj1Pvc"
      },
      "source": [
        "#Plot our original image\n",
        "plt.imshow(input_image.reshape(32,32,3).astype(int))\n",
        "plt.show()\n",
        "\n",
        "#Plot our saliency map: the brighter, the higher the saliency\n",
        "plt.imshow(sal_array.reshape(32,32,3))\n",
        "plt.show()\n",
        "\n",
        "#Plot our saliency map superimposed on the image\n",
        "plt.imshow(input_image.reshape(32,32,3).astype(int))\n",
        "plt.imshow(sal_array.reshape(32,32,3),alpha=0.6)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fistwbaDp56y"
      },
      "source": [
        "We now have some insight into our neural network! We know which pixels matter in its decisions.\n",
        "\n",
        "You can experiment with the definition of saliency we used above; you might come up with a better way to measure it!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# ü§î Knowledge Check\n",
        "\n",
        "Great job getting through this notebook! If you have time, feel free to go back to the optional sections before this section to delve deeper.\n",
        "\n",
        "Feel free to use the below questions to ensure you've learned everything from this notebook!\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yswq2Dyvd6jU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown *1. In this notebook, you implemented an example of computer vision! What is computer vision?*\n",
        "answer_1 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown *2. What's the difference between a color and grayscale (black-and-white) image, in terms of how they're stored in the computer?*\n",
        "answer_2 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown *3. What is a \"neuron\" in a neural network?*\n",
        "answer_3 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown *4. What are we changing in a neural network when we train it?*\n",
        "answer_4 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "handle_discussion_response(answer_1, answer_2, answer_3, answer_4)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hU3rmEDFTQHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you went through the optional/advanced sections, you can try these questions out too!"
      ],
      "metadata": {
        "id": "9coK3eblTlnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown *1. How does a K-nearest neighbors (KNN) classifier make its prediction?*\n",
        "answer_1 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown *2. How do we know if a model is overfitting using the training and validation curves?*\n",
        "answer_2 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "#@markdown *3. What is a saliency map?*\n",
        "answer_3 = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "handle_discussion_response(answer_1, answer_2, answer_3)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kl2R3g_XTPzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instructor Solution  \n",
        "<details><summary>click to reveal!</summary>\n",
        "\n",
        "\n",
        "1. Computer vision is a field of AI that enables machines to interpret and understand visual information from the world, such as images and videos.\n",
        "2. Color images will have to have multiple numbers per pixel to encode the color, whereas grayscale only needs one value to encode the brightness of the pixel. RGB is typically used for color images, where each pixel has 3 different values corresponding to the brightnesses of Red, Green and Blue subpixels\n",
        "3. A neuron is a basic unit that takes input, applies weights to it, and passes it through an activation function to produce an output.\n",
        "4. The weights and biases. Recall that the weights are values that determine the strength of the connection between each neuron, since we multiply the inputs to a neurons by its weights as the first step. The biases are a value that each neuron adds to these weighted inputs before putting its output through the activation function, thereby biasing the output in a particular direction.\n",
        "\n",
        "Optional/advanced questions:\n",
        "1. A KNN classifier uses a number $k$ that you choose and looks at the $k$ pieces of data from the training dataset that are closest to the data you're predicting on. Whatever the majority of those $k$ data points' classifications are, the KNN will choose that as the classification. For example, if we gave our dog vs. road classifier an image, it would find the $k$ most similar images, and predict dog if they were mostly dogs, or road if they were mostly roads.\n",
        "2. Overfitting occurs when the training curve keeps improving while the validation curve starts to degrade after a certain point, indicating the model is learning the noise in the training data rather than generalizing to new data.\n",
        "3. A saliency map is a visual representation that highlights which parts of an image are most important for a model's prediction."
      ],
      "metadata": {
        "id": "eDaPsGFcT3WZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# üìã Cheat Sheets\n",
        "\n",
        "Feel free to use the following cheat sheets as a quick reference!\n",
        "\n",
        "- [Scikit-learn Pipeline Cheat Sheet](https://docs.google.com/document/d/1NK3wvy9pnpg6vab6AkdzLwGSsNf31NSIsrEYz1IVljk/edit?tab=t.53r5m2rr4htd)\n",
        "- [Scikit-learn Models Cheat Sheet](https://docs.google.com/document/d/1NK3wvy9pnpg6vab6AkdzLwGSsNf31NSIsrEYz1IVljk/edit?pli=1&tab=t.ievqibqbhol1)\n",
        "\n",
        "Note that there are more cheat sheets on this document that aren't relevant until later in the program, but feel free to start looking through everything!"
      ],
      "metadata": {
        "id": "XPr7W1g93cSe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVzEpI_xWpE5"
      },
      "source": [
        "---\n",
        "---\n",
        "<h2>Hopefully your neural networks worked <i>very</i> well! We want to keep the puppies as safe as they can be.\n",
        "\n",
        "![](https://images.pexels.com/photos/316/black-and-white-animal-dog-pet.jpg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (Optional reference) How to Use a `for` Loop in Python"
      ],
      "metadata": {
        "id": "BGPXO0mm8Uc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "In Python, a `for` loop is used to iterate over a sequence (like a list, tuple, string, or range) and perform an operation on each item.\n",
        "\n",
        "Basic Syntax:\n",
        "```python\n",
        "for item in sequence:\n",
        "    # Code to execute for each item (indented using spaces!)\n",
        "```\n",
        "- `item`: The variable that takes the value of each element in the sequence during each iteration.\n",
        "- `sequence`: The collection of items you're looping through (e.g., list, string, range, etc.).\n",
        "\n",
        "---\n",
        "\n",
        "Example 1: Looping through a list\n",
        "```python\n",
        "fruits = ['apple', 'banana', 'cherry']\n",
        "for fruit in fruits:\n",
        "    print(fruit)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "apple\n",
        "banana\n",
        "cherry\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "Example 2: Looping through a range of numbers\n",
        "```python\n",
        "for i in range(5):\n",
        "    print(i)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "```\n",
        "In the `range(5)` example, the loop iterates from `0` to `4`. This can also be used if you want to repeat a chunk of code a certain number of times (5 in this case)!"
      ],
      "metadata": {
        "id": "7TFBIR268SgW"
      }
    }
  ]
}